{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **KDDCup Data Analytics with PySpark RDD: A structured case study**"
      ],
      "metadata": {
        "id": "tQWyvE6oKP34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YouTube channel: Code with Kristi\n",
        "## Tutor: Dr Sachin Saxena (PhD, MTech, BTech)"
      ],
      "metadata": {
        "id": "OfJ9r2fSKh8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data source: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html"
      ],
      "metadata": {
        "id": "zS3wzWb8Kmyf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk0qcfhTIPsY"
      },
      "outputs": [],
      "source": [
        "########## ONLY in Colab ##########\n",
        "# !pip3 install pyspark\n",
        "########## ONLY in Colab ##########"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W7a7_biMNn9",
        "outputId": "f51e72cf-10a3-4ee3-8287-b685f5aa5984"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L5nlRpG_WYjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ititialize Spark content\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "conf = SparkConf().setAppName('SivaBigData17MB').setMaster('local[*]')\n",
        "sc=SparkContext(conf=conf)\n",
        "print(sc)\n",
        "print('Ready to Go!!!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYTMPcZzNm9E",
        "outputId": "21513e3e-caec-4647-924f-9f5080d2ed34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SparkContext master=local[*] appName=SivaBigData17MB>\n",
            "Ready to Go!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read and load data to Spark\n",
        "rdd = sc.textFile('/content/drive/MyDrive/Big Data Pyspark Project/kddcup.data.gz')"
      ],
      "metadata": {
        "id": "C4g4j7mSMccO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repartition and Cache Data:"
      ],
      "metadata": {
        "id": "q2cfL1eVOUWT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many partitions do we have?\n",
        "# By default, the number of partitions is determined by the number of cores available\n",
        "# in your local setup or cluster.\n",
        "# If you are running it locally, it's often based on the number of CPU cores.\n",
        "rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hhj6cAHOZQw",
        "outputId": "060c9adf-827a-4acc-d19c-75a9f6595d7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "dctlJdikWDGk",
        "outputId": "fc893947-1dc0-4cd5-c2c7-105ff02945e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.glom().map(len).collect()\n",
        "\n",
        "# glom(): Transforms each partition of the RDD into a list. Instead of working with individual elements, you now have a list of elements for each partition.\n",
        "\n",
        "# map(len): Applies the len function to each partition (which is now a list) to get the count of elements in that partition.\n",
        "\n",
        "# collect(): Collects the result back to the driver as a list, giving the count of elements in each partition."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDLSwlK9Osgt",
        "outputId": "e28fe9ab-b864-4f12-b071-b1e291e5265f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4898431]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the contents of the RDD\n",
        "# print(rdd.collect())"
      ],
      "metadata": {
        "id": "PJEIdXXQV4U2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd =rdd.repartition(10)\n",
        "\n",
        "# Can increase or decrease the level of parallelism in this RDD.\n",
        "# Internally, this uses a shuffle to redistribute data.\n",
        "# If you are decreasing the number of partitions in this RDD, consider using coalesce,\n",
        "#  which can avoid performing a shuffle.\n"
      ],
      "metadata": {
        "id": "VpQyCebVV1GY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.glom().map(len).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP1G91PtXNNt",
        "outputId": "9b83aa1f-15c0-4c2d-cf1f-d8fbd29627ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[489850,\n",
              " 489850,\n",
              " 489850,\n",
              " 489830,\n",
              " 489850,\n",
              " 489850,\n",
              " 489840,\n",
              " 489831,\n",
              " 489830,\n",
              " 489850]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc.defaultParallelism)\n",
        "print(rdd.getNumPartitions())\n",
        "\n",
        "rdd.persist()\n",
        "# 2 cores and 10 partitions, 5 partitions in each core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA2DqwYlXIzg",
        "outputId": "40a4fa21-bab9-4210-fc80-49f29af43bad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MapPartitionsRDD[12] at coalesce at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom dataset"
      ],
      "metadata": {
        "id": "Rr1a72ZSPZD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your list of data\n",
        "data = [('Siva',30), ('Sachin',25),('Manish',41),('Lavya',47),('Varun',72)]\n",
        "\n"
      ],
      "metadata": {
        "id": "VL55PmjTOe8Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHFt8wMUP0XC",
        "outputId": "adf09a92-eea4-42ca-dd96-746ed57f0c9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list into an RDD\n",
        "rdd = sc.parallelize(data)"
      ],
      "metadata": {
        "id": "ryCPYIntP3OF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the contents of the RDD\n",
        "print(rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN5FXHqFP1re",
        "outputId": "18a13b64-ff73-4283-eaaf-4e32a0315bc5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Siva', 30), ('Sachin', 25), ('Manish', 41), ('Lavya', 47), ('Varun', 72)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "lI6oat15QIRE",
        "outputId": "f3f0f085-cb75-4a28-9372-9d8cfe754b7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.glom().map(len).collect()\n",
        "\n",
        "# [number of partitions, elements in each list]\n",
        "# For example, if the RDD is divided into 2 partitions like this:\n",
        "\n",
        "# Partition 1: [('Lavya', 47), ('Varun', 72)]\n",
        "# Partition 2: [('Siva', 30), ('Sachin', 25), ('Manish', 41)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNwuG8kqQK4e",
        "outputId": "9c5b635f-4a60-405d-a4de-3d404a80a109"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RDD with a specific number of partitions (e.g., 5 partitions)\n",
        "\n",
        "rdd = sc.parallelize(data, 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "hLZVpov0Sxdy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of partitions again\n",
        "\n",
        "num_partitions = rdd.getNumPartitions()"
      ],
      "metadata": {
        "id": "gEmLhJm1S4W3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_partitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gol4xfQdS_g3",
        "outputId": "4872b6f8-3d21-46cd-e8f0-74b48060e0a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.glom().map(len).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZA4LmI0TBXt",
        "outputId": "85ae5e0e-7054-4708-84cd-6ec44b8d22c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc.defaultParallelism)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD3Go3kmVR8B",
        "outputId": "53830df7-81f6-40b5-9ada-b66dea565cc7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWpOfAwvVVCr",
        "outputId": "6df17f78-c022-470d-d690-2e9139b001bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.persist()\n",
        "# Set this RDDâ€™s storage level to persist its values across operations after\n",
        "# the first time it is computed. This can only be used to\n",
        "# assign a new storage level if the RDD does not have a storage level set yet."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgaA6XltVYoP",
        "outputId": "9da265e4-f7c1-4b4c-9252-d317c01cfd3d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[8] at readRDDFromFile at PythonRDD.scala:289"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11TgetyhVcUq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}